import streamlit as st
import pandas as pd
import json
import pyodbc
from sqlalchemy import create_engine, text
import plotly.express as px
import plotly.graph_objects as go
from datetime import datetime, timedelta
import os

# è¨­å®šé é¢é…ç½®
st.set_page_config(
    page_title="YS ETL ç›£æ§å„€è¡¨æ¿",
    page_icon="ğŸ“Š",
    layout="wide",
    initial_sidebar_state="expanded"
)

# CSS é¢¨æ ¼
st.markdown("""
<style>
    .main {
        padding: 1rem 2rem;
    }
    .stTabs [data-baseweb="tab-list"] {
        gap: 1rem;
    }
    .stTabs [data-baseweb="tab"] {
        font-size: 1rem;
        padding: 0.5rem 1rem;
    }
    .metric-box {
        background-color: #f8f9fa;
        border-radius: 10px;
        padding: 20px;
        box-shadow: 2px 2px 5px rgba(0,0,0,0.1);
        margin-bottom: 20px;
    }
    .status-success {
        color: green;
        font-weight: bold;
    }
    .status-warning {
        color: orange;
        font-weight: bold;
    }
    .status-error {
        color: red;
        font-weight: bold;
    }
    .st-emotion-cache-6qob1r.eczjsme3 {
        font-weight: bold;
    }
</style>
""", unsafe_allow_html=True)

# è¼‰å…¥è³‡æ–™åº«é…ç½®


@st.cache_data
def load_db_config():
    try:
        with open('db.json', 'r', encoding='utf-8') as f:
            return json.load(f)
    except Exception as e:
        st.error(f"è¼‰å…¥è³‡æ–™åº«é…ç½®å¤±æ•—: {e}")
        return None

# å»ºç«‹è³‡æ–™åº«é€£æ¥


def build_connection_string(db_config):
    drv = "{ODBC Driver 17 for SQL Server}"
    srv = db_config['server']
    port = db_config.get('port', 1433)
    db = db_config['database']
    uid = db_config['username']
    pwd = db_config['password']
    opts = db_config.get('options', {})
    enc = 'yes' if opts.get('encrypt') else 'no'
    trust = 'yes' if opts.get('trustServerCertificate') else 'no'
    conn_str = (
        f"DRIVER={drv};"
        f"SERVER={srv},{port};DATABASE={db};"
        f"UID={uid};PWD={pwd};Encrypt={enc};TrustServerCertificate={trust};"
    )
    return conn_str


def build_sqlalchemy_engine(db_config):
    drv = 'ODBC Driver 17 for SQL Server'.replace(' ', '+')
    srv = db_config['server']
    port = db_config.get('port', 1433)
    db = db_config['database']
    uid = db_config['username']
    pwd = db_config['password']
    opts = db_config.get('options', {})
    enc = 'yes' if opts.get('encrypt') else 'no'
    trust = 'yes' if opts.get('trustServerCertificate') else 'no'
    uri = (
        f"mssql+pyodbc://{uid}:{pwd}@{srv},{port}/{db}?driver={drv}"
        f"&Encrypt={enc}&TrustServerCertificate={trust}"
    )
    return create_engine(uri)

# ç²å–è³‡æ–™è¡¨çµæ§‹ - ä¿®æ­£å¼•æ“åƒæ•¸


@st.cache_data
def get_table_structure(_engine, table_name):
    try:
        query = f"""
        SELECT 
            COLUMN_NAME, 
            DATA_TYPE, 
            CHARACTER_MAXIMUM_LENGTH,
            NUMERIC_PRECISION,
            NUMERIC_SCALE,
            IS_NULLABLE,
            ORDINAL_POSITION
        FROM INFORMATION_SCHEMA.COLUMNS 
        WHERE TABLE_NAME = '{table_name}'
        ORDER BY ORDINAL_POSITION
        """
        return pd.read_sql(query, _engine)
    except Exception as e:
        st.error(f"ç²å–è¡¨æ ¼çµæ§‹å¤±æ•—: {e}")
        return pd.DataFrame()

# ç²å–è³‡æ–™åº«ä¸­æ‰€æœ‰è¡¨æ ¼ - ä¿®æ­£å¼•æ“åƒæ•¸


@st.cache_data
def get_all_tables(_engine):
    try:
        query = """
        SELECT TABLE_NAME 
        FROM INFORMATION_SCHEMA.TABLES 
        WHERE TABLE_TYPE = 'BASE TABLE'
        ORDER BY TABLE_NAME
        """
        return pd.read_sql(query, _engine)
    except Exception as e:
        st.error(f"ç²å–è¡¨æ ¼åˆ—è¡¨å¤±æ•—: {e}")
        return pd.DataFrame()

# ç²å–è¡¨æ ¼è³‡æ–™ç¯„ä¾‹ - ä¿®æ­£å¼•æ“åƒæ•¸


@st.cache_data(ttl=300)  # 5åˆ†é˜ç·©å­˜
def get_table_sample(_engine, table_name, limit=100):
    try:
        query = f"SELECT TOP {limit} * FROM {table_name}"
        return pd.read_sql(query, _engine)
    except Exception as e:
        st.error(f"ç²å–è¡¨æ ¼è³‡æ–™ç¯„ä¾‹å¤±æ•—: {e}")
        return pd.DataFrame()

# ç²å–è¡¨æ ¼è³‡æ–™æ•¸é‡ - ä¿®æ­£å¼•æ“åƒæ•¸


@st.cache_data(ttl=300)  # 5åˆ†é˜ç·©å­˜
def get_table_count(_engine, table_name):
    try:
        query = f"SELECT COUNT(*) AS row_count FROM {table_name}"
        return pd.read_sql(query, _engine).iloc[0]['row_count']
    except Exception as e:
        st.error(f"ç²å–è¡¨æ ¼è³‡æ–™æ•¸é‡å¤±æ•—: {e}")
        return 0

# ç²å– ETL åŸ·è¡Œè¨˜éŒ„ - ä¿®æ­£å¼•æ“åƒæ•¸


@st.cache_data(ttl=300)  # 5åˆ†é˜ç·©å­˜
def get_etl_summary(_engine, days=7):
    try:
        # æª¢æŸ¥è¡¨æ˜¯å¦å­˜åœ¨
        check_query = """
        SELECT CASE WHEN EXISTS (
            SELECT * FROM INFORMATION_SCHEMA.TABLES 
            WHERE TABLE_NAME = 'ETL_SUMMARY'
        ) THEN 1 ELSE 0 END AS table_exists
        """
        exists = pd.read_sql(check_query, _engine).iloc[0]['table_exists']

        if not exists:
            return None

        recent_date = datetime.now() - timedelta(days=days)

        # ç²å–æ¯æ—¥åŸ·è¡Œçµ±è¨ˆï¼Œéæ¿¾æ‰æ‘˜è¦è¨˜éŒ„
        daily_stats_query = f"""
        SELECT 
            CONVERT(VARCHAR(10), ETL_DATE, 120) AS ExecutionDate,
            COUNT(*) AS TotalExecutions,
            SUM(CASE WHEN SOURCE_TYPE = 'MES' THEN 1 ELSE 0 END) AS MESExecutions,
            SUM(CASE WHEN SOURCE_TYPE = 'SAP' THEN 1 ELSE 0 END) AS SAPExecutions,
            SUM([ROW_COUNT]) AS TotalRowsProcessed
        FROM ETL_SUMMARY
        WHERE ETL_DATE >= '{recent_date.strftime('%Y-%m-%d')}'
        AND SUMMARY_TYPE = 'QUERY'  -- åªé¸æ“‡æŸ¥è©¢åŸ·è¡Œè¨˜éŒ„
        GROUP BY CONVERT(VARCHAR(10), ETL_DATE, 120)
        ORDER BY ExecutionDate DESC
        """

        daily_stats = pd.read_sql(daily_stats_query, _engine)

        # ç²å–æœ€è¿‘åŸ·è¡Œè¨˜éŒ„ï¼Œéæ¿¾æ‰ç„¡æ„ç¾©çš„è¨˜éŒ„
        recent_query = """
        SELECT TOP 50
            [TIMESTAMP],
            [SOURCE_TYPE],
            [QUERY_NAME],
            [TARGET_TABLE],
            [ROW_COUNT],
            CONVERT(VARCHAR(19), ETL_DATE, 120) AS ETL_DATE
        FROM ETL_SUMMARY
        WHERE [SOURCE_TYPE] IS NOT NULL 
          AND [SOURCE_TYPE] <> '' 
          AND [SOURCE_TYPE] <> 'None'
          AND [QUERY_NAME] IS NOT NULL 
          AND [QUERY_NAME] <> '' 
          AND [QUERY_NAME] <> 'None'
        ORDER BY [ETL_DATE] DESC
        """

        recent_executions = pd.read_sql(recent_query, _engine)

        # ç²å–å„ç›®æ¨™è¡¨çš„è¨˜éŒ„æ•¸ï¼Œéæ¿¾æ‰ç„¡æ„ç¾©çš„è¨˜éŒ„
        table_stats_query = """
        SELECT 
            s.TARGET_TABLE,
            CONVERT(VARCHAR(19), MAX(s.ETL_DATE), 120) AS LastUpdated,
            MAX(s.[ROW_COUNT]) AS [Total_Rows]
        FROM ETL_SUMMARY s
        INNER JOIN (
            SELECT TARGET_TABLE, MAX(ETL_DATE) AS MaxDate
            FROM ETL_SUMMARY
            WHERE TARGET_TABLE IS NOT NULL 
              AND TARGET_TABLE <> '' 
              AND TARGET_TABLE <> 'None'
              AND TARGET_TABLE <> 'ALL_TABLES'
            GROUP BY TARGET_TABLE
        ) latest ON s.TARGET_TABLE = latest.TARGET_TABLE AND s.ETL_DATE = latest.MaxDate
        WHERE s.TARGET_TABLE IS NOT NULL 
          AND s.TARGET_TABLE <> '' 
          AND s.TARGET_TABLE <> 'None'
          AND s.TARGET_TABLE <> 'ALL_TABLES'
        GROUP BY s.TARGET_TABLE
        """

        table_stats = pd.read_sql(table_stats_query, _engine)

        return {
            'daily_stats': daily_stats,
            'recent_executions': recent_executions,
            'table_stats': table_stats
        }
    except Exception as e:
        st.error(f"ç²å– ETL åŸ·è¡Œè¨˜éŒ„å¤±æ•—: {e}")
        return None

# ç²å–ä¸€å€‹æ¬„ä½çš„è³‡æ–™åˆ†ä½ˆ - ä¿®æ­£å¼•æ“åƒæ•¸


@st.cache_data(ttl=300)  # 5åˆ†é˜ç·©å­˜
def get_column_distribution(_engine, table_name, column_name, limit=1000):
    try:
        # æª¢æŸ¥æ¬„ä½é¡å‹
        structure = get_table_structure(_engine, table_name)
        col_info = structure[structure['COLUMN_NAME'] == column_name]

        if col_info.empty:
            return None

        data_type = col_info.iloc[0]['DATA_TYPE']

        # æ ¹æ“šæ•¸æ“šé¡å‹é¸æ“‡ä¸åŒçš„æŸ¥è©¢
        if data_type in ('varchar', 'nvarchar', 'char', 'nchar', 'text', 'ntext'):
            # æ–‡å­—é¡æ¬„ä½
            query = f"""
            SELECT TOP {limit} 
                {column_name} AS value, 
                COUNT(*) AS count
            FROM {table_name}
            WHERE {column_name} IS NOT NULL
            GROUP BY {column_name}
            ORDER BY COUNT(*) DESC
            """
        elif data_type in ('int', 'bigint', 'smallint', 'tinyint', 'decimal', 'numeric', 'float', 'real', 'money', 'smallmoney'):
            # æ•¸å€¼é¡æ¬„ä½
            query = f"""
            SELECT TOP {limit} 
                {column_name} AS value, 
                COUNT(*) AS count
            FROM {table_name}
            WHERE {column_name} IS NOT NULL
            GROUP BY {column_name}
            ORDER BY {column_name}
            """
        elif data_type in ('date', 'datetime', 'datetime2', 'smalldatetime'):
            # æ—¥æœŸé¡æ¬„ä½
            query = f"""
            SELECT TOP {limit} 
                CONVERT(VARCHAR(10), {column_name}, 120) AS value, 
                COUNT(*) AS count
            FROM {table_name}
            WHERE {column_name} IS NOT NULL
            GROUP BY CONVERT(VARCHAR(10), {column_name}, 120)
            ORDER BY CONVERT(VARCHAR(10), {column_name}, 120)
            """
        else:
            # å…¶ä»–é¡å‹
            query = f"""
            SELECT TOP {limit} 
                CAST({column_name} AS VARCHAR(100)) AS value, 
                COUNT(*) AS count
            FROM {table_name}
            WHERE {column_name} IS NOT NULL
            GROUP BY {column_name}
            ORDER BY COUNT(*) DESC
            """

        result = pd.read_sql(query, _engine)
        result['value'] = result['value'].astype(str)  # ç¢ºä¿å€¼ç‚ºå­—ä¸²é¡å‹
        return result
    except Exception as e:
        st.error(f"ç²å–æ¬„ä½åˆ†ä½ˆå¤±æ•—: {e}")
        return None

# ä¸»æ‡‰ç”¨ç¨‹å¼


def main():
    st.title("YS ETL ç›£æ§å„€è¡¨æ¿")

    # åˆå§‹åŒ–
    configs = load_db_config()
    if not configs:
        st.error("ç„¡æ³•åŠ è¼‰è³‡æ–™åº«é…ç½®ã€‚è«‹ç¢ºä¿ db.json æ–‡ä»¶å­˜åœ¨ä¸¦æ ¼å¼æ­£ç¢ºã€‚")
        return

    # å´é‚Šæ¬„
    st.sidebar.header("è³‡æ–™åº«é€£æ¥")

    db_type = st.sidebar.selectbox(
        "é¸æ“‡è³‡æ–™åº«é¡å‹",
        ["Tableau (ç›®æ¨™)", "MES (ä¾†æº)", "SAP (ä¾†æº)"]
    )

    if db_type == "Tableau (ç›®æ¨™)":
        db_config = configs.get('tableau_db')
    elif db_type == "MES (ä¾†æº)":
        db_config = configs.get('mes_db')
    else:  # SAP (ä¾†æº)
        db_config = configs.get('sap_db')

    if not db_config:
        st.sidebar.error(f"æ‰¾ä¸åˆ° {db_type} çš„è³‡æ–™åº«é…ç½®")
        return

    st.sidebar.success(f"å·²é€£æ¥åˆ° {db_config['server']}/{db_config['database']}")

    # å»ºç«‹è³‡æ–™åº«å¼•æ“
    engine = build_sqlalchemy_engine(db_config)

    # ä¸»æ¨™ç±¤
    tabs = st.tabs(["å„€è¡¨æ¿", "è¡¨æ ¼çµæ§‹", "è³‡æ–™æ¢ç´¢", "ETL åŸ·è¡Œè¨˜éŒ„"])

    # å„€è¡¨æ¿æ¨™ç±¤
    with tabs[0]:
        st.header("ETL æ¦‚æ³å„€è¡¨æ¿")

        # ç²å– ETL æ‘˜è¦
        etl_summary = get_etl_summary(engine)

        # ç„¡ ETL æ‘˜è¦æ™‚çš„æç¤º
        if not etl_summary:
            st.warning("æ‰¾ä¸åˆ° ETL åŸ·è¡Œè¨˜éŒ„ã€‚è«‹ç¢ºä¿ ETL_SUMMARY è¡¨å­˜åœ¨ä¸”æœ‰è³‡æ–™ã€‚")
            st.info("æ‚¨å¯ä»¥å…ˆæŸ¥çœ‹ã€Œè¡¨æ ¼çµæ§‹ã€å’Œã€Œè³‡æ–™æ¢ç´¢ã€æ¨™ç±¤ä¾†äº†è§£è³‡æ–™åº«ä¸­çš„è³‡æ–™ã€‚")
        else:
            # è¨ˆç®—æ‘˜è¦æŒ‡æ¨™
            total_executions = len(etl_summary['recent_executions'])
            unique_tables = etl_summary['table_stats']['TARGET_TABLE'].nunique(
            )
            total_rows = etl_summary['table_stats']['Total_Rows'].sum()

            # æœ€è¿‘ä¸€æ¬¡åŸ·è¡Œæ™‚é–“
            latest_execution = None
            if not etl_summary['recent_executions'].empty:
                latest_execution = etl_summary['recent_executions'].iloc[0]['ETL_DATE']

            # å„€è¡¨æ¿æŒ‡æ¨™
            col1, col2, col3 = st.columns(3)

            with col1:
                st.markdown("<div class='metric-box'>", unsafe_allow_html=True)
                st.metric("ç¸½åŸ·è¡Œæ¬¡æ•¸", f"{total_executions:,}")

                if latest_execution:
                    st.markdown(f"æœ€è¿‘åŸ·è¡Œ: {latest_execution}")
                st.markdown("</div>", unsafe_allow_html=True)

            with col2:
                st.markdown("<div class='metric-box'>", unsafe_allow_html=True)
                st.metric("ç›®æ¨™è¡¨æ•¸é‡", unique_tables)

                # ç•¶å¤©æ˜¯å¦åŸ·è¡Œ
                today = datetime.now().strftime('%Y-%m-%d')
                today_executions = etl_summary['daily_stats'][etl_summary['daily_stats']
                                                              ['ExecutionDate'] == today]

                if not today_executions.empty:
                    st.markdown(
                        "<span class='status-success'>âœ“ ä»Šæ—¥å·²åŸ·è¡Œ</span>", unsafe_allow_html=True)
                else:
                    st.markdown(
                        "<span class='status-warning'>âš  ä»Šæ—¥å°šæœªåŸ·è¡Œ</span>", unsafe_allow_html=True)
                st.markdown("</div>", unsafe_allow_html=True)

            with col3:
                st.markdown("<div class='metric-box'>", unsafe_allow_html=True)
                st.metric("ç¸½è™•ç†è³‡æ–™é‡", f"{total_rows:,} ç­†")

                # é¡¯ç¤ºæˆåŠŸç‡
                success_count = etl_summary['recent_executions'].shape[0]
                if success_count > 0:
                    st.markdown(
                        "<span class='status-success'>åŸ·è¡ŒæˆåŠŸç‡: 100%</span>", unsafe_allow_html=True)
                st.markdown("</div>", unsafe_allow_html=True)

            # æ¯æ—¥åŸ·è¡Œçµ±è¨ˆåœ–è¡¨
            st.subheader("æ¯æ—¥åŸ·è¡Œçµ±è¨ˆ")

            if not etl_summary['daily_stats'].empty:
                daily_stats = etl_summary['daily_stats'].copy()
                # è½‰æ›æ—¥æœŸç‚ºæ—¥æœŸé¡å‹ä»¥ä¾¿æ’åº
                daily_stats['ExecutionDate'] = pd.to_datetime(
                    daily_stats['ExecutionDate'])
                daily_stats = daily_stats.sort_values('ExecutionDate')

                fig = go.Figure()

                # MES åŸ·è¡Œæ¬¡æ•¸
                fig.add_trace(go.Bar(
                    x=daily_stats['ExecutionDate'],
                    y=daily_stats['MESExecutions'],
                    name='MES åŸ·è¡Œæ¬¡æ•¸',
                    marker_color='rgba(55, 83, 109, 0.7)'
                ))

                # SAP åŸ·è¡Œæ¬¡æ•¸
                fig.add_trace(go.Bar(
                    x=daily_stats['ExecutionDate'],
                    y=daily_stats['SAPExecutions'],
                    name='SAP åŸ·è¡Œæ¬¡æ•¸',
                    marker_color='rgba(26, 118, 255, 0.7)'
                ))

                fig.update_layout(
                    barmode='group',
                    xaxis_title='åŸ·è¡Œæ—¥æœŸ',
                    yaxis_title='åŸ·è¡Œæ¬¡æ•¸',
                    xaxis=dict(
                        tickformat='%Y-%m-%d',
                        tickangle=-45
                    ),
                    template='plotly_white',
                    height=400
                )

                st.plotly_chart(fig, use_container_width=True)
            else:
                st.info("ç„¡æ¯æ—¥åŸ·è¡Œçµ±è¨ˆè³‡æ–™")

            # è³‡æ–™è™•ç†é‡è¶¨å‹¢åœ–
            st.subheader("è³‡æ–™è™•ç†é‡è¶¨å‹¢")

            if not etl_summary['daily_stats'].empty:
                daily_stats = etl_summary['daily_stats'].copy()
                # è½‰æ›æ—¥æœŸç‚ºæ—¥æœŸé¡å‹ä»¥ä¾¿æ’åº
                daily_stats['ExecutionDate'] = pd.to_datetime(
                    daily_stats['ExecutionDate'])
                daily_stats = daily_stats.sort_values('ExecutionDate')

                fig = px.line(
                    daily_stats,
                    x='ExecutionDate',
                    y='TotalRowsProcessed',
                    markers=True,
                    labels={'ExecutionDate': 'åŸ·è¡Œæ—¥æœŸ',
                            'TotalRowsProcessed': 'è™•ç†è³‡æ–™é‡'}
                )

                fig.update_layout(
                    xaxis_title='åŸ·è¡Œæ—¥æœŸ',
                    yaxis_title='è™•ç†è³‡æ–™é‡',
                    xaxis=dict(
                        tickformat='%Y-%m-%d',
                        tickangle=-45
                    ),
                    template='plotly_white',
                    height=400
                )

                st.plotly_chart(fig, use_container_width=True)
            else:
                st.info("ç„¡è³‡æ–™è™•ç†é‡è¶¨å‹¢è³‡æ–™")

            # è¡¨æ ¼çµ±è¨ˆ
            st.subheader("ç›®æ¨™è¡¨æœ€æ–°ç‹€æ…‹")

            if not etl_summary['table_stats'].empty:
                # æ ¼å¼åŒ–æ—¥æœŸæ™‚é–“åˆ—
                etl_summary['table_stats']['LastUpdated'] = pd.to_datetime(
                    etl_summary['table_stats']['LastUpdated'])

                fig = px.bar(
                    etl_summary['table_stats'].sort_values(
                        'Total_Rows', ascending=False),
                    x='TARGET_TABLE',
                    y='Total_Rows',
                    color='Total_Rows',
                    labels={'TARGET_TABLE': 'ç›®æ¨™è¡¨', 'Total_Rows': 'è³‡æ–™åˆ—æ•¸'},
                    hover_data=['LastUpdated']
                )

                fig.update_layout(
                    xaxis_title='ç›®æ¨™è¡¨',
                    yaxis_title='è³‡æ–™åˆ—æ•¸',
                    xaxis_tickangle=-45,
                    template='plotly_white',
                    height=400
                )

                st.plotly_chart(fig, use_container_width=True)

                # é¡¯ç¤ºè¡¨æ ¼è©³ç´°è³‡è¨Š
                st.dataframe(
                    etl_summary['table_stats'],
                    column_config={
                        "TARGET_TABLE": "ç›®æ¨™è¡¨",
                        "LastUpdated": st.column_config.DatetimeColumn("æœ€è¿‘æ›´æ–°æ™‚é–“"),
                        "Total_Rows": st.column_config.NumberColumn("è³‡æ–™åˆ—æ•¸", format="%d")
                    },
                    hide_index=True
                )
            else:
                st.info("ç„¡ç›®æ¨™è¡¨çµ±è¨ˆè³‡æ–™")

            # æœ€è¿‘åŸ·è¡Œè¨˜éŒ„
            st.subheader("æœ€è¿‘åŸ·è¡Œè¨˜éŒ„")

            if not etl_summary['recent_executions'].empty:
                # æ ¼å¼åŒ–æ—¥æœŸæ™‚é–“åˆ—
                etl_summary['recent_executions']['ETL_DATE'] = pd.to_datetime(
                    etl_summary['recent_executions']['ETL_DATE'])

                st.dataframe(
                    etl_summary['recent_executions'],
                    column_config={
                        "TIMESTAMP": "æ™‚é–“æˆ³è¨˜",
                        "SOURCE_TYPE": "ä¾†æºé¡å‹",
                        "QUERY_NAME": "æŸ¥è©¢åç¨±",
                        "TARGET_TABLE": "ç›®æ¨™è¡¨",
                        "ROW_COUNT": st.column_config.NumberColumn("è³‡æ–™åˆ—æ•¸", format="%d"),
                        "ETL_DATE": st.column_config.DatetimeColumn("ETL åŸ·è¡Œæ™‚é–“")
                    },
                    hide_index=True
                )
            else:
                st.info("ç„¡æœ€è¿‘åŸ·è¡Œè¨˜éŒ„")

    # è¡¨æ ¼çµæ§‹æ¨™ç±¤
    with tabs[1]:
        st.header("è³‡æ–™è¡¨çµæ§‹ç€è¦½")

        # ç²å–æ‰€æœ‰è¡¨æ ¼
        tables = get_all_tables(engine)

        if tables.empty:
            st.warning("è³‡æ–™åº«ä¸­æœªæ‰¾åˆ°è¡¨æ ¼")
            return

        # é¸æ“‡è¡¨æ ¼
        selected_table = st.selectbox("é¸æ“‡è³‡æ–™è¡¨", tables['TABLE_NAME'])

        # é¡¯ç¤ºè¡¨æ ¼çµæ§‹
        st.subheader(f"{selected_table} è¡¨æ ¼çµæ§‹")

        structure = get_table_structure(engine, selected_table)
        if not structure.empty:
            # è½‰æ›æ¬„ä½é¡å‹ä¿¡æ¯
            def format_type(row):
                type_str = row['DATA_TYPE']

                if type_str in ('varchar', 'nvarchar', 'char', 'nchar'):
                    length = row['CHARACTER_MAXIMUM_LENGTH']
                    if length == -1:
                        type_str += '(MAX)'
                    elif length is not None:
                        type_str += f'({length})'
                elif type_str in ('decimal', 'numeric'):
                    precision = row['NUMERIC_PRECISION']
                    scale = row['NUMERIC_SCALE']
                    if precision is not None and scale is not None:
                        type_str += f'({precision},{scale})'

                return type_str

            structure['DATA_TYPE_FORMATTED'] = structure.apply(
                format_type, axis=1)
            structure['IS_NULLABLE'] = structure['IS_NULLABLE'].apply(
                lambda x: 'æ˜¯' if x == 'YES' else 'å¦')

            # é¡¯ç¤ºè¡¨æ ¼çµæ§‹è³‡æ–™
            st.dataframe(
                structure[['COLUMN_NAME', 'DATA_TYPE_FORMATTED',
                           'IS_NULLABLE', 'ORDINAL_POSITION']],
                column_config={
                    "COLUMN_NAME": "æ¬„ä½åç¨±",
                    "DATA_TYPE_FORMATTED": "è³‡æ–™é¡å‹",
                    "IS_NULLABLE": "å…è¨±NULL",
                    "ORDINAL_POSITION": "é †åº"
                },
                hide_index=True
            )

            # é¡¯ç¤ºè³‡æ–™è¡¨çµ±è¨ˆä¿¡æ¯
            row_count = get_table_count(engine, selected_table)
            st.metric("è³‡æ–™åˆ—æ•¸", f"{row_count:,}")
        else:
            st.warning(f"ç„¡æ³•ç²å– {selected_table} çš„è¡¨æ ¼çµæ§‹")

    # è³‡æ–™æ¢ç´¢æ¨™ç±¤
    with tabs[2]:
        st.header("è³‡æ–™æ¢ç´¢")

        # ç²å–æ‰€æœ‰è¡¨æ ¼
        tables = get_all_tables(engine)

        if tables.empty:
            st.warning("è³‡æ–™åº«ä¸­æœªæ‰¾åˆ°è¡¨æ ¼")
            return

        # é¸æ“‡è¡¨æ ¼
        selected_table = st.selectbox(
            "é¸æ“‡è³‡æ–™è¡¨", tables['TABLE_NAME'], key="explore_table")

        # ç²å–è¡¨æ ¼çµæ§‹
        structure = get_table_structure(engine, selected_table)
        if structure.empty:
            st.warning(f"ç„¡æ³•ç²å– {selected_table} çš„è¡¨æ ¼çµæ§‹")
            return

        # ç²å–è¡¨æ ¼ç¯„ä¾‹æ•¸æ“š
        sample_size = st.slider("ç¯„ä¾‹è³‡æ–™é‡", min_value=5,
                                max_value=1000, value=100, step=5)
        sample_data = get_table_sample(engine, selected_table, sample_size)

        # é¡¯ç¤ºè¡¨æ ¼ç¯„ä¾‹æ•¸æ“š
        st.subheader(f"{selected_table} ç¯„ä¾‹è³‡æ–™")

        if not sample_data.empty:
            st.dataframe(sample_data)
        else:
            st.warning(f"ç„¡æ³•ç²å– {selected_table} çš„ç¯„ä¾‹è³‡æ–™")
            return

        # æ¬„ä½åˆ†æ
        st.subheader("æ¬„ä½åˆ†æ")

        # é¸æ“‡æ¬„ä½
        columns = structure['COLUMN_NAME'].tolist()
        selected_column = st.selectbox("é¸æ“‡è¦åˆ†æçš„æ¬„ä½", columns)

        # ç²å–æ¬„ä½åˆ†ä½ˆ
        column_data = get_column_distribution(
            engine, selected_table, selected_column)

        if column_data is not None and not column_data.empty:
            # çµ±è¨ˆä¿¡æ¯
            total_values = column_data['count'].sum()
            unique_values = len(column_data)

            col1, col2 = st.columns(2)

            with col1:
                st.metric("å”¯ä¸€å€¼æ•¸é‡", unique_values)

            with col2:
                st.metric("ç¸½å€¼æ•¸é‡", f"{total_values:,}")

            # ç¹ªè£½åˆ†ä½ˆåœ–
            # å¦‚æœå”¯ä¸€å€¼å¤ªå¤šï¼Œåªé¡¯ç¤ºå‰20é …
            display_limit = 20
            if len(column_data) > display_limit:
                st.info(
                    f"è©²æ¬„ä½æœ‰ {len(column_data)} å€‹å”¯ä¸€å€¼ï¼Œä¸‹åœ–åªé¡¯ç¤ºå‰ {display_limit} é …ã€‚")
                plot_data = column_data.head(display_limit)
            else:
                plot_data = column_data

            fig = px.bar(
                plot_data,
                x='value',
                y='count',
                labels={'value': 'å€¼', 'count': 'è¨ˆæ•¸'},
                title=f"{selected_column} æ¬„ä½åˆ†ä½ˆ"
            )

            fig.update_layout(
                xaxis_title=selected_column,
                yaxis_title='è¨ˆæ•¸',
                xaxis_tickangle=-45,
                template='plotly_white',
                height=400
            )

            st.plotly_chart(fig, use_container_width=True)

            # é¡¯ç¤ºåˆ†ä½ˆæ•¸æ“šè¡¨æ ¼
            st.subheader("å€¼åˆ†ä½ˆè¡¨æ ¼")

            # è¨ˆç®—ç™¾åˆ†æ¯”
            column_data['percentage'] = column_data['count'] / \
                column_data['count'].sum() * 100

            st.dataframe(
                column_data,
                column_config={
                    "value": selected_column,
                    "count": st.column_config.NumberColumn("è¨ˆæ•¸", format="%d"),
                    "percentage": st.column_config.NumberColumn("ç™¾åˆ†æ¯”", format="%.2f%%")
                },
                hide_index=True
            )
        else:
            st.warning(f"ç„¡æ³•ç²å– {selected_column} æ¬„ä½çš„åˆ†ä½ˆæ•¸æ“š")

    # ETL åŸ·è¡Œè¨˜éŒ„æ¨™ç±¤
    with tabs[3]:
        st.header("ETL åŸ·è¡Œè¨˜éŒ„")

        # ç²å– ETL æ‘˜è¦
        etl_days = st.slider("é¡¯ç¤ºæœ€è¿‘å¹¾å¤©çš„è¨˜éŒ„", min_value=1,
                             max_value=90, value=30, step=1)
        etl_summary = get_etl_summary(engine, etl_days)

        if not etl_summary:
            st.warning("æ‰¾ä¸åˆ° ETL åŸ·è¡Œè¨˜éŒ„ã€‚è«‹ç¢ºä¿ ETL_SUMMARY è¡¨å­˜åœ¨ä¸”æœ‰è³‡æ–™ã€‚")
            return

        # é¡¯ç¤ºæœ€è¿‘åŸ·è¡Œè¨˜éŒ„
        st.subheader("æœ€è¿‘åŸ·è¡Œè¨˜éŒ„")

        if not etl_summary['recent_executions'].empty:
            # æ ¼å¼åŒ–æ—¥æœŸæ™‚é–“åˆ—
            etl_summary['recent_executions']['ETL_DATE'] = pd.to_datetime(
                etl_summary['recent_executions']['ETL_DATE'])

            # æ·»åŠ éæ¿¾é¸é …
            col1, col2 = st.columns(2)

            with col1:
                source_types = [
                    'å…¨éƒ¨'] + etl_summary['recent_executions']['SOURCE_TYPE'].unique().tolist()
                selected_source = st.selectbox("ä¾†æºé¡å‹", source_types)

            with col2:
                target_tables = [
                    'å…¨éƒ¨'] + etl_summary['recent_executions']['TARGET_TABLE'].unique().tolist()
                selected_table = st.selectbox("ç›®æ¨™è¡¨", target_tables)

            # æ‡‰ç”¨éæ¿¾
            filtered_data = etl_summary['recent_executions'].copy()

            if selected_source != 'å…¨éƒ¨':
                filtered_data = filtered_data[filtered_data['SOURCE_TYPE']
                                              == selected_source]

            if selected_table != 'å…¨éƒ¨':
                filtered_data = filtered_data[filtered_data['TARGET_TABLE']
                                              == selected_table]

            # é¡¯ç¤ºéæ¿¾å¾Œçš„è³‡æ–™
            if not filtered_data.empty:
                st.dataframe(
                    filtered_data,
                    column_config={
                        "TIMESTAMP": "æ™‚é–“æˆ³è¨˜",
                        "SOURCE_TYPE": "ä¾†æºé¡å‹",
                        "QUERY_NAME": "æŸ¥è©¢åç¨±",
                        "TARGET_TABLE": "ç›®æ¨™è¡¨",
                        "ROW_COUNT": st.column_config.NumberColumn("è³‡æ–™åˆ—æ•¸", format="%d"),
                        "ETL_DATE": st.column_config.DatetimeColumn("ETL åŸ·è¡Œæ™‚é–“")
                    },
                    hide_index=True
                )
            else:
                st.info("ç¬¦åˆéæ¿¾æ¢ä»¶çš„è¨˜éŒ„ç‚ºç©º")

            # ç¹ªè£½åŸ·è¡Œè¨˜éŒ„è¶¨å‹¢åœ–
            st.subheader("åŸ·è¡Œè¨˜éŒ„è¶¨å‹¢")

            # æŒ‰æ—¥æœŸåˆ†çµ„
            etl_summary['recent_executions']['ETL_DATE_DATE'] = etl_summary['recent_executions']['ETL_DATE'].dt.date
            daily_counts = etl_summary['recent_executions'].groupby(
                ['ETL_DATE_DATE', 'SOURCE_TYPE']).size().reset_index(name='count')

            if not daily_counts.empty:
                fig = px.line(
                    daily_counts,
                    x='ETL_DATE_DATE',
                    y='count',
                    color='SOURCE_TYPE',
                    markers=True,
                    labels={'ETL_DATE_DATE': 'æ—¥æœŸ',
                            'count': 'åŸ·è¡Œæ¬¡æ•¸', 'SOURCE_TYPE': 'ä¾†æºé¡å‹'}
                )

                fig.update_layout(
                    xaxis_title='æ—¥æœŸ',
                    yaxis_title='åŸ·è¡Œæ¬¡æ•¸',
                    xaxis_tickangle=-45,
                    template='plotly_white',
                    height=400
                )

                st.plotly_chart(fig, use_container_width=True)
            else:
                st.info("ç„¡åŸ·è¡Œè¨˜éŒ„è¶¨å‹¢è³‡æ–™")

            # ç›®æ¨™è¡¨æ›´æ–°æ™‚é–“è¡¨æ ¼
            st.subheader("ç›®æ¨™è¡¨æœ€å¾Œæ›´æ–°æ™‚é–“")

            if not etl_summary['table_stats'].empty:
                etl_summary['table_stats']['LastUpdated'] = pd.to_datetime(
                    etl_summary['table_stats']['LastUpdated'])

                st.dataframe(
                    etl_summary['table_stats'],
                    column_config={
                        "TARGET_TABLE": "ç›®æ¨™è¡¨",
                        "LastUpdated": st.column_config.DatetimeColumn("æœ€è¿‘æ›´æ–°æ™‚é–“"),
                        "Total_Rows": st.column_config.NumberColumn("è³‡æ–™åˆ—æ•¸", format="%d")
                    },
                    hide_index=True
                )
            else:
                st.info("ç„¡ç›®æ¨™è¡¨æ›´æ–°æ™‚é–“è³‡æ–™")
        else:
            st.info("ç„¡ ETL åŸ·è¡Œè¨˜éŒ„è³‡æ–™")

    # é è…³
    st.markdown("---")
    st.markdown(
        f"<div style='text-align: center; color: gray; font-size: 0.8em;'>"
        f"YS ETL ç›£æ§å„€è¡¨æ¿ | æœ€å¾Œæ›´æ–°æ™‚é–“: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}"
        f"</div>",
        unsafe_allow_html=True
    )


if __name__ == "__main__":
    main()
